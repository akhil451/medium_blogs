{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c018b792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lmdb\n",
      "  Downloading lmdb-1.3.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (305 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.9/305.9 KB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lmdb\n",
      "Successfully installed lmdb-1.3.0\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-7.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from pyarrow) (1.21.5)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-7.0.0\n",
      "Requirement already satisfied: ffcv in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (0.0.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (4.63.0)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (0.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (1.4.1)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (5.9.0)\n",
      "Requirement already satisfied: fastargs in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (1.2.0)\n",
      "Requirement already satisfied: assertpy in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (1.1)\n",
      "Requirement already satisfied: webdataset in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (0.1.103)\n",
      "Requirement already satisfied: imgcat in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (0.5.0)\n",
      "Requirement already satisfied: pytorch-pfn-extras in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (0.5.7)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (3.5.1)\n",
      "Requirement already satisfied: terminaltables in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from ffcv) (3.1.10)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from matplotlib->ffcv) (4.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from matplotlib->ffcv) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from matplotlib->ffcv) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from matplotlib->ffcv) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from matplotlib->ffcv) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from matplotlib->ffcv) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from matplotlib->ffcv) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from matplotlib->ffcv) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from pandas->ffcv) (2021.3)\n",
      "Requirement already satisfied: typing-extensions>=3.10 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from pytorch-pfn-extras->ffcv) (4.1.1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from pytorch-pfn-extras->ffcv) (1.10.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from sklearn->ffcv) (1.0.2)\n",
      "Requirement already satisfied: braceexpand in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from webdataset->ffcv) (0.1.7)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from webdataset->ffcv) (6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->ffcv) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from scikit-learn->sklearn->ffcv) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from scikit-learn->sklearn->ffcv) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages (from scikit-learn->sklearn->ffcv) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install lmdb \n",
    "! pip install pyarrow\n",
    "! pip install ffcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1f34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import multiprocessing\n",
    "import pyarrow as pa\n",
    "import lmdb\n",
    "import numpy as np\n",
    "num_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cabb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"temp/insect_25/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5724612d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc775b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True).to(device)\n",
    "    \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False   \n",
    "    \n",
    "model.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 25)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68b062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': \n",
    "    datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n",
    "    'validation': \n",
    "    datasets.ImageFolder(input_path + 'val', data_transforms['validation'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "    torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                batch_size=256,\n",
    "                                shuffle=True,\n",
    "                                num_workers=multiprocessing.cpu_count()),  # for Kaggle\n",
    "    'validation':\n",
    "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
    "                                batch_size=256,\n",
    "                                shuffle=False,\n",
    "                                num_workers=multiprocessing.cpu_count())  # for Kaggle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d1eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92dddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa258ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "865f4811-6d50-4530-80c6-92a7b9acfccb",
   "metadata": {},
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "#     print('-' * 10)\n",
    "    start = time.time()\n",
    "    \n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "    \n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(image_datasets[phase])\n",
    "        epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "    print(\"Time taken in 1 epoch\", time.time()-start, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de193e6",
   "metadata": {},
   "source": [
    "### create lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9946877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pyarrow as pa\n",
    "import lmdb\n",
    "num_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfba32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_reader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        bin_data = f.read()\n",
    "    return bin_data\n",
    "\n",
    "\n",
    "def dumps_pyarrow(obj):\n",
    "    \"\"\"\n",
    "    Serialize an object.\n",
    "    Returns:\n",
    "        Implementation-dependent bytes-like object\n",
    "    \"\"\"\n",
    "    return pa.serialize(obj).to_buffer()\n",
    "\n",
    "def folder2lmdb(path, outpath, write_frequency=5000):\n",
    "    directory = os.path.expanduser(path)\n",
    "    print(\"Loading dataset from %s\" % directory)\n",
    "    dataset = ImageFolder(directory, loader=raw_reader)\n",
    "    data_loader = DataLoader(dataset, collate_fn=lambda x: x,num_workers=num_workers)\n",
    "    lmdb_path = os.path.expanduser(outpath)\n",
    "    isdir = os.path.isdir(lmdb_path)\n",
    "\n",
    "    print(\"Generate LMDB to %s\" % lmdb_path)\n",
    "    db = lmdb.open(lmdb_path, subdir=isdir,\n",
    "                   map_size=1099511627776 * 2, readonly=False,\n",
    "                   meminit=False, map_async=True)\n",
    "\n",
    "    txn = db.begin(write=True)\n",
    "    for idx, data in enumerate(data_loader):\n",
    "        image, label = data[0]\n",
    "        txn.put(u'{}'.format(idx).encode('ascii'), dumps_pyarrow((image, label)))\n",
    "        if idx % write_frequency == 0:\n",
    "            print(\"[%d/%d]\" % (idx, len(data_loader)))\n",
    "            txn.commit()\n",
    "            txn = db.begin(write=True)\n",
    "    print(\"LABEL:\", label)\n",
    "    # finish iterating through dataset\n",
    "    txn.commit()\n",
    "    keys = [u'{}'.format(k).encode('ascii') for k in range(idx + 1)]\n",
    "    with db.begin(write=True) as txn:\n",
    "        txn.put(b'__keys__', dumps_pyarrow(keys))\n",
    "        txn.put(b'__len__', dumps_pyarrow(len(keys)))\n",
    "\n",
    "    print(\"Flushing database ...\")\n",
    "    db.sync()\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae758fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderLMDB(Dataset):\n",
    "    def __init__(self, db_path, transform=None, target_transform=None):\n",
    "        self.db_path = db_path\n",
    "        self.env = lmdb.open(db_path, subdir=os.path.isdir(db_path),\n",
    "                             readonly=True, lock=False,\n",
    "                             readahead=False, meminit=False)\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            self.length = pa.deserialize(txn.get(b'__len__'))\n",
    "            self.keys = pa.deserialize(txn.get(b'__keys__'))\n",
    "\n",
    "        self.transform = transform\n",
    "#         print(self.transform)\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         print(index)\n",
    "        img, target = None, None\n",
    "        env = self.env\n",
    "        with env.begin(write=False) as txn:\n",
    "            byteflow = txn.get(self.keys[index])\n",
    "        unpacked = pa.deserialize(byteflow)\n",
    "\n",
    "        # load image\n",
    "        imgbuf = unpacked[0]\n",
    "        buf = six.BytesIO()\n",
    "        buf.write(imgbuf)\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf).convert('RGB')\n",
    "        img= np.array(img)\n",
    "        # load label\n",
    "        target = unpacked[1]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image = img)[\"image\"]\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "#         print(type(img),img.numpy().shape)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + self.db_path + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38854189",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir  = os.path.join(\"temp/insect_25/train\")\n",
    "train_db_path  = \"temp/insect_25/train-lmdb\"\n",
    "val_dir  = os.path.join(\"temp/insect_25/val\")\n",
    "val_db_path  = \"temp/insect_25/val-lmdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9aff0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96974f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from temp/insect_25/train\n",
      "Generate LMDB to temp/insect_25/train-lmdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/6349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000/6349]\n",
      "LABEL: 24\n",
      "Flushing database ...\n",
      "Loading dataset from temp/insect_25/val\n",
      "Generate LMDB to temp/insect_25/val-lmdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/714]\n",
      "LABEL: 24\n",
      "Flushing database ...\n",
      "CPU times: user 3.6 s, sys: 2.38 s, total: 5.97 s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "folder2lmdb(train_dir, train_db_path)\n",
    "folder2lmdb(val_dir, val_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e7b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "143f0b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3343: FutureWarning: 'pyarrow.deserialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3343: FutureWarning: 'pyarrow.deserialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ImageFolderLMDB(\n",
    "        train_db_path,\n",
    "           data_transforms['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce7b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ImageFolderLMDB(\n",
    "        val_db_path,\n",
    "        data_transforms['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26d0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "#         train_dataset, batch_size=16*torch.cuda.device_count(), shuffle=True,\n",
    "        train_dataset, batch_size=256,shuffle=False,num_workers=multiprocessing.cpu_count())\n",
    "        #, pin_memory=T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adf38986",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "#         val_dataset, batch_size=8*torch.cuda.device_count(),shuffle=True,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f97ad065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:819: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in 1 epoch 47.67885661125183 seconds.\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:819: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in 1 epoch 48.91055727005005 seconds.\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:819: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in 1 epoch 51.61034798622131 seconds.\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:819: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in 1 epoch 53.74762797355652 seconds.\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:819: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in 1 epoch 55.84217572212219 seconds.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "#     print('-' * 10)\n",
    "    start = time.time()\n",
    "    \n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "    \n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(image_datasets[phase])\n",
    "        epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "    print(\"Time taken in 1 epoch\", time.time()-start, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9392d",
   "metadata": {},
   "source": [
    "#### using ffcv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa1e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffcv.pipeline.operation import Operation\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import ToTensor, ToDevice, Squeeze, NormalizeImage, \\\n",
    "    RandomHorizontalFlip, ToTorchImage\n",
    "from ffcv.fields.rgb_image import CenterCropRGBImageDecoder, \\\n",
    "    RandomResizedCropRGBImageDecoder,ResizedCropRGBImageDecoder\n",
    "from ffcv.fields.basics import IntDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a3aecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc94e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406]) * 255\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225]) * 255\n",
    "DEFAULT_CROP_RATIO = 224/256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef76462",
   "metadata": {},
   "source": [
    "### create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d18b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffcv.writer import DatasetWriter\n",
    "from ffcv.fields import RGBImageField, IntField\n",
    "\n",
    "# Your dataset (`torch.utils.data.Dataset`) of (image, label) pairs\n",
    "import multiprocessing\n",
    "num_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0d2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_beton_file(write_path,my_dataset):\n",
    "    # Pass a type for each data field\n",
    "    writer = DatasetWriter(write_path, {\n",
    "        # Tune options to optimize dataset size, throughput at train-time\n",
    "        'image': RGBImageField(max_resolution=256, jpeg_quality=100),\n",
    "        'label': IntField()\n",
    "    },num_workers=num_workers)\n",
    "\n",
    "    # Write dataset\n",
    "    writer.from_indexed_dataset(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0df333fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_path = \"temp/insect_25/train.beton\"\n",
    "val_loader_path = \"temp/insect_25/val.beton\"\n",
    "batch_size=256\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b7a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = \"temp/insect_25/train\"\n",
    "train_dataset= ImageFolder(train_directory)\n",
    "val_directory = \"temp/insect_25/val\"\n",
    "val_dataset= ImageFolder(val_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d872e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 714/714 [00:19<00:00, 37.51it/s]\n",
      "  6%|▋         | 400/6349 [00:07<01:21, 73.23it/s]/home/ec2-user/anaconda3/envs/ffcv/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 6349/6349 [01:32<00:00, 68.80it/s] \n"
     ]
    }
   ],
   "source": [
    "save_beton_file(val_loader_path,val_dataset)\n",
    "save_beton_file(train_loader_path,train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8344b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3df0b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # this changes in ddp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410b488c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bc3e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (224, 224)\n",
    "decoder = CenterCropRGBImageDecoder(size, ratio=DEFAULT_CROP_RATIO)\n",
    "\n",
    "# Data decoding and augmentation\n",
    "train_image_pipeline = [decoder,RandomHorizontalFlip(), ToTensor(), ToDevice(device, non_blocking=True),ToTorchImage(),\n",
    "            NormalizeImage(IMAGENET_MEAN, IMAGENET_STD, np.float32)]\n",
    "label_pipeline = [IntDecoder(), ToTensor(), ToDevice(0)]\n",
    "val_image_pipeline = [decoder, ToTensor(), ToDevice(device, non_blocking=True),ToTorchImage(),\n",
    "            NormalizeImage(IMAGENET_MEAN, IMAGENET_STD, np.float32)]\n",
    "# Replaces PyTorch data loader (`torch.utils.data.Dataloader`)\n",
    "train_loader = Loader(train_loader_path, batch_size=batch_size, num_workers=num_workers,\n",
    "                order=OrderOption.RANDOM, pipelines={\n",
    "    'image': train_image_pipeline,\n",
    "    'label': label_pipeline\n",
    "}\n",
    ")\n",
    "val_loader = Loader(val_loader_path, batch_size=batch_size, num_workers=num_workers,\n",
    "                order=OrderOption.RANDOM, pipelines={\n",
    "    'image': val_image_pipeline,\n",
    "    'label': label_pipeline\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46a6d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "import time\n",
    "# batchwiselogs= open(base_save_folder+\"/500-insectsb4-batchwiselogs.txt\",\"w\")\n",
    "# epoch_timings =  open(base_save_folder+\"/500-insectsb4-epochwiselogs.txt\",\"w\")\n",
    "best_accuracy=0\n",
    "epoch_txts=[]\n",
    "best_epoch_accuracy =0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20946203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Time_taken for 1 epoch: 21.419193267822266\n",
      "epoch: 1\n",
      "Time_taken for 1 epoch: 21.823665380477905\n",
      "epoch: 2\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    logs = {}\n",
    "    start = time.time()\n",
    "    print(\"epoch:\",epoch)\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    batch_number =0 \n",
    "#     t1 = time.time()\n",
    "    model.train()\n",
    "#     print(epoch_txt)\n",
    "    start = time.time()\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "#         print(data,label)\n",
    "        batch_time_start = time.time()\n",
    "        batch_number+=1\n",
    "        data = data.to(device,dtype=torch.float)\n",
    "        label = label.to(device,dtype=torch.int64)\n",
    "\n",
    "\n",
    "        output = model(data)\n",
    "        label_ = torch.squeeze(label)\n",
    "#         print(\"label.shape,data.shape,output[0].shape,label_.shape: \",label.shape,data.shape,output[0].shape,label_.shape)\n",
    "#         input()\n",
    "#         import pdb \n",
    "#         pdb.set_trace()\n",
    "        loss = criterion(output, label_)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == label).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "        if epoch_accuracy>best_epoch_accuracy:\n",
    "            best_epoch_accuracy = epoch_accuracy\n",
    "        time_taken = time.time() - batch_time_start\n",
    "        text_to_write = \"Batch number: \"+ str(batch_number)+\", time_taken: \"+str(time_taken)+\"\\n\"\n",
    "#         print(text_to_write)\n",
    "#         batchwiselogs.write(text_to_write)\n",
    "#         t1= time.time()\n",
    "        \n",
    "    logs['training_loss'] = epoch_loss.item()\n",
    "    logs['training_accuracy'] = epoch_accuracy.item()\n",
    "# #     print(logs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        model.eval()\n",
    "        for data, label in val_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            label_ = torch.squeeze(label)\n",
    "            val_loss = criterion(val_output, label_)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            \n",
    "            epoch_val_accuracy += acc / len(val_loader)\n",
    "            epoch_val_loss += val_loss / len(val_loader)\n",
    "            if epoch_val_accuracy > best_accuracy :\n",
    "                best_accuracy = epoch_val_accuracy\n",
    "                if not os.path.exists(\"artifacts\"):\n",
    "                    os.makedirs(\"artifacts\")\n",
    "#                 torch.save(model.state_dict(), base_save_folder+'/epoch_'+str(epoch)+'_accuracy_'+str(epoch_val_accuracy)+'.pt')\n",
    "    print(\"Time_taken for 1 epoch:\",time.time()-start)\n",
    "#     scheduler.step(epoch_val_loss)\n",
    "    logs['validation_loss'] = epoch_val_loss.item()\n",
    "    logs['validation_accuracy'] = epoch_val_accuracy.item()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4579ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
